{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3817ab2-2541-4131-8102-40bd8d1bad48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from bs4 import BeautifulSoup # type: ignore\n",
    "import httpx # type: ignore\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "import pandas as pd # type: ignore\n",
    "from datetime import datetime, timedelta\n",
    "from io import StringIO\n",
    "from urllib import parse\n",
    "from typing import Dict, Any, Tuple, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c255d13b-23ce-4d3c-809c-241e3172a153",
   "metadata": {},
   "outputs": [],
   "source": [
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6dba43a4-8abf-4703-b6ec-3c8ceef1d1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.gcpmanager import BQManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "825c7870-161f-4c8a-a620-580ae31cb616",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaverNews:\n",
    "    \"\"\"Independent Naver news pipeline (no NaverCrawler dependency).\"\"\"\n",
    "    def __init__(self, bq_manager: Optional[BQManager] = None):\n",
    "        if not bq_manager:\n",
    "            bq_manager = BQManager()\n",
    "        self.bq_manager = bq_manager\n",
    "            \n",
    "        self.client = httpx.AsyncClient(headers={\n",
    "            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36'\n",
    "        }, follow_redirects=True)\n",
    "\n",
    "    async def collect(self, query: str, max_articles: int = 100):\n",
    "        table_id = f\"news-naver-{query}\"\n",
    "\n",
    "        enc_text = parse.quote(query)\n",
    "        api_url = f\"https://openapi.naver.com/v1/search/news.json?query={enc_text}&display={max_articles}\"\n",
    "\n",
    "        client_id = 'YOUR_NAVER_CLIENT_ID'\n",
    "        client_secret = 'YOUR_NAVER_CLIENT_SECRET'\n",
    "        api_headers = {\n",
    "            \"X-Naver-Client-Id\": client_id,\n",
    "            \"X-Naver-Client-Secret\": client_secret\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            response = await self.client.get(api_url, headers=api_headers)\n",
    "            response.raise_for_status()\n",
    "            search_result = response.json()\n",
    "            news_list = search_result.get('items', [])\n",
    "            yield {\"type\": \"progress\", \"step\": \"api_call\", \"status\": \"done\", \"total\": len(news_list)}\n",
    "\n",
    "        except Exception as e:\n",
    "            yield {\"type\": \"error\", \"message\": f\"API request failed: {e}\"}\n",
    "            return\n",
    "\n",
    "        scraped_treasures: list[dict] = []\n",
    "        total_articles = len(news_list)\n",
    "        for i, news_item in enumerate(news_list):\n",
    "            news_url = news_item.get('link')\n",
    "            if not news_url or 'news.naver.com' not in news_url:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                yield {\"type\": \"progress\", \"step\": \"scraping\", \"current\": i + 1, \"total\": total_articles}\n",
    "                response = await self.client.get(news_url)\n",
    "                response.raise_for_status()\n",
    "                soup = BeautifulSoup(response.text, HTML_PARSER)\n",
    "\n",
    "                title = soup.select_one('h2#title_area')\n",
    "                content = soup.select_one('div#newsct_article')\n",
    "                press = soup.select_one('img.media_end_head_top_logo_img') \n",
    "\n",
    "                cleaned_title = title.get_text(strip=True) if title else \"제목 없음\"\n",
    "                cleaned_content = content.get_text(strip=True) if content else \"본문 없음\"\n",
    "                cleaned_press = press['alt'] if press and 'alt' in press.attrs else \"언론사 불명\"\n",
    "\n",
    "                treasure_box = {\n",
    "                    'search_keyword': query,\n",
    "                    'original_link': news_url,\n",
    "                    'title': cleaned_title,\n",
    "                    'press': cleaned_press,\n",
    "                    'content': cleaned_content[:500],\n",
    "                    'crawled_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "                }\n",
    "                scraped_treasures.append(treasure_box)\n",
    "                await asyncio.sleep(random.uniform(0.1, 0.3))\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error scraping {news_url}: {e}\")\n",
    "                continue\n",
    "\n",
    "        if not scraped_treasures:\n",
    "            yield {\"type\": \"result\", \"data\": []}\n",
    "            return\n",
    "\n",
    "        yield {\"type\": \"progress\", \"step\": \"saving\", \"status\": \"saving to BigQuery\"}\n",
    "        _ = self._prepare_and_save_news_data(scraped_treasures, table_id)\n",
    "        yield {\"type\": \"result\", \"data\": {\"saved\": len(scraped_treasures)}}\n",
    "\n",
    "    async def process(self, query: str, limit: int | None = None):\n",
    "        table_id = f\"news-naver-{query}\"\n",
    "        cached_df = self.bq_manager.query_table(table_id=table_id, order_by_date=False)\n",
    "        if cached_df is None or cached_df.empty:\n",
    "            yield {\"type\": \"result\", \"data\": []}\n",
    "            return\n",
    "        if 'crawled_at' in cached_df.columns:\n",
    "            cached_df['crawled_at'] = pd.to_datetime(cached_df['crawled_at']).dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        cached_df.fillna('', inplace=True)\n",
    "        if 'content' in cached_df.columns:\n",
    "            cached_df['content'] = cached_df['content'].str.slice(0, 500)\n",
    "        if limit is not None:\n",
    "            cached_df = cached_df.head(limit)\n",
    "        yield {\"type\": \"result\", \"data\": cached_df.to_dict(orient='records')}\n",
    "\n",
    "    def _prepare_and_save_news_data(self, treasures: list[dict], table_id: str) -> pd.DataFrame:\n",
    "        df_treasures = pd.DataFrame(treasures)\n",
    "        self.bq_manager.load_dataframe(\n",
    "            df=df_treasures,\n",
    "            table_id=table_id,\n",
    "            if_exists=\"append\",\n",
    "            deduplicate_on=['original_link']\n",
    "        )\n",
    "        return df_treasures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fdcb5695-5436-471f-b2a5-1b1e64924ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaverMarket:\n",
    "    def __init__(self, \n",
    "                 bq_manager: Optional[BQManager] = None, \n",
    "                 company_dict: Optional[Any] = None, \n",
    "                 company: Optional[str] = None):\n",
    "        \n",
    "        if company_dict:\n",
    "            self.company_dict = company_dict\n",
    "        \n",
    "        if bq_manager:\n",
    "            self.bq_manager = bq_manager\n",
    "        else:\n",
    "            self.bq_manager = BQManager()\n",
    "\n",
    "        self._header = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36',\n",
    "            'Accept' : \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7\"\n",
    "        }\n",
    "        self.base_url = 'https://finance.naver.com'\n",
    "        self.company = company or '005930'\n",
    "        self.bq_manager = bq_manager\n",
    "        self.company_dict = company_dict\n",
    "        self.client = httpx.AsyncClient(headers=self._header, follow_redirects=True)\n",
    "\n",
    "    async def market_collect(self, company: str | None = None, start_date: str | None = None, end_date: str | None = None, max_page: int = 10):\n",
    "        if company:\n",
    "            self.company = company\n",
    "\n",
    "        if not end_date:\n",
    "            end_date = datetime.now().strftime('%Y-%m-%d')\n",
    "        if not start_date:\n",
    "            start_date = (datetime.now() - timedelta(days=180)).strftime('%Y-%m-%d')\n",
    "        \n",
    "        company_name = self.company_dict.get_company_by_code(self.company) or self.company\n",
    "        table_id = f\"market-naverfinance-{company_name}\"\n",
    "\n",
    "        crawled_df = pd.DataFrame()\n",
    "        async for progress_update in _crawl_price_history(self.company, self.client, max_page=max_page):\n",
    "            if progress_update[\"type\"] == \"progress\":\n",
    "                yield progress_update\n",
    "            elif progress_update[\"type\"] == \"result\":\n",
    "                crawled_df = progress_update[\"data\"]\n",
    "\n",
    "        if crawled_df.empty:\n",
    "            yield {\"type\": \"error\", \"message\": \"Failed to crawl market data.\"}\n",
    "            return\n",
    "\n",
    "        # Filter by date range\n",
    "        crawled_df = crawled_df[\n",
    "            (crawled_df['date'] >= pd.to_datetime(start_date)) &\n",
    "            (crawled_df['date'] <= pd.to_datetime(end_date))\n",
    "        ]\n",
    "\n",
    "        yield {\"type\": \"progress\", \"step\": \"saving\", \"status\": \"saving to BigQuery\"}\n",
    "        df_saved = self._prepare_and_save_market_data(crawled_df, table_id)\n",
    "        yield {\"type\": \"result\", \"data\": {\"saved\": len(df_saved)}}\n",
    "    \n",
    "    def _prepare_and_save_market_data(self, df: pd.DataFrame, table_id: str) -> pd.DataFrame:\n",
    "        \"\"\"Clean market dataframe and persist to BigQuery in one step.\n",
    "\n",
    "        - Ensures required columns and types\n",
    "        - Adds code/source columns\n",
    "        - Saves to BigQuery with deduplication\n",
    "        - Returns the dataframe that was saved\n",
    "        \"\"\"\n",
    "        df_for_bq = df.copy()\n",
    "        if 'date' in df_for_bq.columns:\n",
    "            df_for_bq['date'] = pd.to_datetime(df_for_bq['date']).dt.date\n",
    "\n",
    "        for col in ['open', 'high', 'low', 'close', 'volume']:\n",
    "            if col in df_for_bq.columns:\n",
    "                df_for_bq[col] = pd.to_numeric(df_for_bq[col], errors='coerce').fillna(0)\n",
    "                if col == 'volume':\n",
    "                    df_for_bq[col] = df_for_bq[col].astype('int64')\n",
    "                else:\n",
    "                    df_for_bq[col] = df_for_bq[col].astype(float)\n",
    "\n",
    "        df_for_bq['code'] = self.company\n",
    "        df_for_bq['source'] = 'naver'\n",
    "\n",
    "        self.bq_manager.load_dataframe(\n",
    "            df=df_for_bq,\n",
    "            table_id=table_id,\n",
    "            if_exists=\"append\",\n",
    "            deduplicate_on=['date', 'code']\n",
    "        )\n",
    "\n",
    "        return df_for_bq\n",
    "\n",
    "    async def _get_market_cap(self):\n",
    "        \"\"\"현재 종목의 시가총액을 스크래핑하여 숫자로 반환합니다.\"\"\"\n",
    "        try:\n",
    "            url = f'https://finance.naver.com/item/sise.naver?code={self.company}'\n",
    "            response = await self.client.get(url)\n",
    "            response.raise_for_status()\n",
    "            soup = BeautifulSoup(response.text, HTML_PARSER)\n",
    "            \n",
    "            market_sum_tag = soup.select_one('#_market_sum')\n",
    "            if market_sum_tag:\n",
    "                market_sum_text = market_sum_tag.get_text(strip=True)\n",
    "                \n",
    "                market_sum = 0\n",
    "                parts = market_sum_text.replace(',', '').split('조')\n",
    "                if len(parts) > 1:\n",
    "                    market_sum += int(parts[0]) * 1_0000_0000_0000\n",
    "                    remaining = parts[1]\n",
    "                else:\n",
    "                    remaining = parts[0]\n",
    "                \n",
    "                if '억' in remaining:\n",
    "                    market_sum += int(remaining.replace('억', '')) * 1_0000_0000\n",
    "                \n",
    "                return market_sum\n",
    "            return 0\n",
    "        except Exception:\n",
    "            return 0\n",
    "    \n",
    "    async def market_process(self, company: str | None = None):\n",
    "        if company:\n",
    "            self.company = company\n",
    "        \n",
    "        company_name = self.company_dict.get_company_by_code(self.company) or self.company\n",
    "        table_id = f\"market-naverfinance-{company_name}\"\n",
    "        \n",
    "        cached_df = self.bq_manager.query_table(table_id=table_id, order_by_date=True)\n",
    "        \n",
    "        if cached_df is None or cached_df.empty:\n",
    "            yield {\"type\": \"result\", \"data\": {}}\n",
    "            return\n",
    "\n",
    "        formatted_data = await self._format_response_from_df(cached_df)\n",
    "        yield {\"type\": \"result\", \"data\": formatted_data}\n",
    "\n",
    "    async def _format_response_from_df(self, df: pd.DataFrame):\n",
    "        company_name = self.company_dict.get_company_by_code(self.company) or self.company\n",
    "        market_cap = await self._get_market_cap()\n",
    "\n",
    "        if df is None or df.empty:\n",
    "            return {\n",
    "                \"name\": company_name,\n",
    "                \"source\": \"naver\",\n",
    "                \"currentPrice\": {\"value\": 0, \"changePercent\": 0},\n",
    "                \"volume\": {\"value\": 0, \"changePercent\": 0},\n",
    "                \"marketCap\": {\"value\": market_cap, \"changePercent\": 0},\n",
    "                \"priceHistory\": [],\n",
    "                \"volumeHistory\": [],\n",
    "            }\n",
    "            \n",
    "        df.sort_values(by='date', ascending=False, inplace=True)\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        latest = df.iloc[0]\n",
    "        previous = df.iloc[1] if len(df) > 1 else latest\n",
    "\n",
    "        price_change_percent = ((latest['close'] - previous['close']) / previous['close']) * 100 if previous['close'] != 0 else 0\n",
    "        volume_change_percent = ((latest['volume'] - previous['volume']) / previous['volume']) * 100 if previous['volume'] != 0 else 0\n",
    "\n",
    "        latest_close = float(latest['close']) if pd.notna(latest['close']) else 0.0\n",
    "        latest_volume = int(latest['volume']) if pd.notna(latest['volume']) else 0\n",
    "\n",
    "        result = {\n",
    "            \"name\": company_name or self.company,\n",
    "            \"source\": \"naver\",\n",
    "            \"currentPrice\": {\n",
    "                \"value\": latest_close,\n",
    "                \"changePercent\": round(price_change_percent, 2)\n",
    "            },\n",
    "            \"volume\": {\n",
    "                \"value\": latest_volume,\n",
    "                \"changePercent\": round(volume_change_percent, 2)\n",
    "            },\n",
    "            \"marketCap\": {\n",
    "                \"value\": market_cap,\n",
    "                \"changePercent\": 0 \n",
    "            },\n",
    "            \"priceHistory\": df.rename(columns={'close': 'price'})[['date', 'price']].to_dict(orient='records'),\n",
    "            \"volumeHistory\": df[['date', 'volume']].to_dict(orient='records')\n",
    "        }\n",
    "\n",
    "        for item in result['priceHistory']:\n",
    "            if isinstance(item['date'], pd.Timestamp):\n",
    "                item['date'] = item['date'].strftime('%Y-%m-%d')\n",
    "\n",
    "        for item in result['volumeHistory']:\n",
    "            if isinstance(item['date'], pd.Timestamp):\n",
    "                item['date'] = item['date'].strftime('%Y-%m-%d')\n",
    "\n",
    "        return result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
